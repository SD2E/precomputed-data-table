{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,json,sys,pyemd\n",
    "from os.path import expanduser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CONVERGE_PROJECT=\"sd2e-project-43\"\n",
    "\n",
    "data_converge_base = os.path.join(expanduser(\"~\"), 'sd2e-projects', DATA_CONVERGE_PROJECT)\n",
    "experiment_dir = os.path.realpath(os.path.join(data_converge_base, 'test/batch_20200525'))\n",
    "experiment_dir_contents = [os.path.realpath(os.path.join(experiment_dir, x)) for x in os.listdir(experiment_dir)]\n",
    "\n",
    "experiments = [x for x in  experiment_dir_contents \n",
    "               if os.path.isdir(x) and \"CRISPR-Short-Duration\" in x]\n",
    "\n",
    "experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Helper functions\n",
    "\n",
    "def get_record(experiment):\n",
    "    record = json.load(open(os.path.join(experiment, \"record.json\")))\n",
    "    return record\n",
    "\n",
    "def get_record_file(record, file_type=\"fc_meta\"):\n",
    "    files = record['files']\n",
    "    files_of_type = [ x for x in files if file_type in x['name']]\n",
    "    if len(files_of_type) > 0:\n",
    "        return files_of_type[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_data(experiment, record, file_type):\n",
    "    fc_raw_file = get_record_file(record, file_type)\n",
    "    if fc_raw_file:\n",
    "        data_df = pd.read_csv(os.path.join(experiment, fc_raw_file['name']))\n",
    "        return data_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_bins(df):\n",
    "    return [float(x.split(\"_\")[1]) for x in df.columns if \"bin\" in x]\n",
    "\n",
    "def get_row_values(df,row_name,id_col):\n",
    "    df_j = df.loc[df[id_col] == row_name]\n",
    "    df_j = df_j[[x for x in df_j.columns if \"bin\" in x]]\n",
    "    return df_j.values[0]\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis functions\n",
    "\n",
    "\n",
    "def emdist(h1, h2, bin_vals):\n",
    "    '''\n",
    "    Calculate earth mover's distance between 2 histograms. Histograms are normalized to mass 1.\n",
    "\n",
    "    :param h1: a 1-D numpy array representing a histogram with the bin values used to make bin_dist\n",
    "    :param h2: a 1-D numpy array representing a histogram with the bin values used to make bin_dist\n",
    "    :param bin_vals: representative points in the bins defining the histograms in data\n",
    "    :return: a scalar value that is the earth mover's distance between normalized h1 and h2\n",
    "    '''\n",
    "    bin_dist = np.array([[np.abs(m - n) for m in bin_vals] for n in bin_vals])\n",
    "    return pyemd.emd(np.asarray(h1)/float(sum(h1)), np.asarray(h2)/float(sum(h2)), bin_dist)\n",
    "\n",
    "\n",
    "def do_analysis(experiment,datafile,id_col=\"sample_id\",channel_col=\"channel\",channel_val=\"BL1-A\"):\n",
    "    # datafile is \"fc_raw_log10_stats.csv\" or \"fc_etl_stats.csv\"\n",
    "\n",
    "    ## load dataset from data converge \n",
    "    record = get_record(experiment)\n",
    "    df = get_data(experiment, record, datafile)\n",
    "    \n",
    "    if df is None:\n",
    "        return None\n",
    "        \n",
    "    df = df.loc[df[channel_col] == channel_val]\n",
    "\n",
    "#     ## Truncated for testing\n",
    "#     df = df.iloc[:5]\n",
    "\n",
    "    bins = get_bins(df)   \n",
    "    ids = list(df[id_col].values)   \n",
    "    res = np.zeros([len(ids),len(ids)])\n",
    "    \n",
    "    for j,s in enumerate(ids):\n",
    "        s_bin_vals = get_row_values(df,s,id_col)\n",
    "        for k,t in enumerate(ids[j+1:]):\n",
    "            t_bin_vals = get_row_values(df,t,id_col)\n",
    "            score = emdist(s_bin_vals, t_bin_vals, bins)\n",
    "            res[j,j+k+1] = 10**score\n",
    "            res[j+k+1,j] = 10**score\n",
    "    df_results = pd.DataFrame(data=res, index=ids, columns=ids)\n",
    "    return df_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Wasserstein analysis on all processed data sets\n",
    "\n",
    "for experiment in experiments:\n",
    "    for datafile in [\"fc_raw_log10_stats.csv\",\"fc_etl_stats.csv\"]:\n",
    "        experiment_name = experiment.split(\"/\")[-1]\n",
    "        print(experiment_name)\n",
    "        print(datafile)\n",
    "        fname = experiment_name+\"_\"+datafile.split(\".\")[0]+\"_wasserstein_dists.csv\"\n",
    "        if not os.path.exists(fname):\n",
    "            df = do_analysis(experiment,datafile)\n",
    "            df.to_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
